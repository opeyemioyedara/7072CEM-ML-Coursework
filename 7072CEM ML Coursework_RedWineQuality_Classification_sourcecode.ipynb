{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64d868a",
   "metadata": {},
   "source": [
    "# Prediction of Wine Quality Classification using Machine Learning Algorithms.\n",
    "\n",
    "# 1. Import all the required libraries and wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79595aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular exploratory data analysis and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to make the plots appear inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Models adopted for coursework from Scikit-Learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model Evaluations\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import scikitplot as skplt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.base import BaseEstimator\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the red wine dataset\n",
    "winedata = pd.read_csv(\"winequality-white.csv\", sep = ';')\n",
    "print (\"wine shape\", winedata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"////// wine data describe ////////\")\n",
    "print(winedata.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51fc9e",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wine dataset shape - \")\n",
    "print(winedata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af10bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "winedata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if any dataset has null feature or label value\n",
    "winedata.isna().sum()\n",
    "# No feature with null value found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d62985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- histogram plot of the attributes distribution -\")\n",
    "winedata.hist(figsize=(12,8),bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the correlation among all the attributes\n",
    "corr_matrix = winedata.corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax = sns.heatmap(corr_matrix,\n",
    "                 annot=True,\n",
    "                 linewidths=0.5,\n",
    "                 fmt=\".2f\",\n",
    "                 cmap=\"YlGnBu\");\n",
    "bottom, top = ax.get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8816cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for count of available data for each class\n",
    "winedata[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd12ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the class imbalances\n",
    "sns.countplot(x=winedata[\"quality\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520edfa",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "\n",
    "### A. Creating 2 classes for wine quality from wine quality score\n",
    "\n",
    "Recategorizing the wine quality unbalanced ordinal class into an unbalanced binary class\n",
    "\n",
    "1. Class 0 (Normal quality wine) : Quality score from 0 to 6\n",
    "2. Class 1 (High quality wine) : Quality score from 7 to 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aada91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isQualitylevel(quality):\n",
    "    if quality >= 7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "winedata[\"quality\"] = winedata[\"quality\"].apply(isQualitylevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "winedata[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the class imbalances\n",
    "sns.countplot(x=winedata[\"quality\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1dbdf7",
   "metadata": {},
   "source": [
    "### B. Split data into X and y (features and target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y (features and target)\n",
    "X = winedata.drop(\"quality\", axis=1)\n",
    "y = winedata[\"quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53b15e",
   "metadata": {},
   "source": [
    "### C. Split X and y into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "np.random.seed(22)\n",
    "\n",
    "X_pretrain, X_pretest, y_pretrain, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pretrain.value_counts(), y_pretrain.value_counts().sum(), y_test.value_counts(), y_test.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eba4c5",
   "metadata": {},
   "source": [
    "### D. Feature Scaling - Standardization of the X_pretrain and X_pretest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of the X_pretrain and X_pretest data\n",
    "scaler = StandardScaler()\n",
    "X_pretrainscaled = scaler.fit_transform(X_pretrain)\n",
    "X_pretrainscaled = pd.DataFrame(X_pretrainscaled, columns=X_pretrain.columns)\n",
    "\n",
    "X_pretestscaled = scaler.transform(X_pretest)\n",
    "X_pretestscaled = pd.DataFrame(X_pretestscaled, columns=X_pretest.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ab4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of the data distribution before scaling and after scaling\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax1.set_title('Before Scaling-X_pretrain')\n",
    "sns.kdeplot(X_pretrain[\"fixed acidity\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"volatile acidity\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"citric acid\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"residual sugar\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"chlorides\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"free sulfur dioxide\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"total sulfur dioxide\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"density\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"pH\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"sulphates\"],ax=ax1)\n",
    "sns.kdeplot(X_pretrain[\"alcohol\"],ax=ax1)\n",
    "\n",
    "ax2.set_title('After Scaling-X_pretrain')\n",
    "sns.kdeplot(X_pretrainscaled[\"fixed acidity\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"volatile acidity\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"citric acid\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"residual sugar\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"chlorides\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"free sulfur dioxide\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"total sulfur dioxide\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"density\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"pH\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"sulphates\"],ax=ax2)\n",
    "sns.kdeplot(X_pretrainscaled[\"alcohol\"],ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8649c",
   "metadata": {},
   "source": [
    "### E. Data imbalance correction - SMOTETomtek link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalaned y_train data\n",
    "sns.countplot(x=y_pretrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolving data imbalance on the training dataset using SMOTE oversampling--remove this approach\n",
    "\n",
    "smote_tomek = SMOTETomek()\n",
    "X_train, y_train = smote_tomek.fit_resample(X_pretrainscaled, y_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanced y_trained data\n",
    "sns.countplot(x=y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"chlorides\"].value_counts().sum(), y_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming X_pretestscaled to X_test for naming uniformity\n",
    "X_test = X_pretestscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a7fd7",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Modeling with default chosen ML estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for the machine learning models\n",
    "\n",
    "models = {\"Logistic Regression\" : LogisticRegression(), \n",
    "          \"KNN\" : KNeighborsClassifier(),\n",
    "          \"Decision Tree\" : DecisionTreeClassifier()}\n",
    "\n",
    "# Create a function to fit and score models\n",
    "\n",
    "def model_fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates the with the 3 selected machine learning models\n",
    "    models : a dict of 3 different Scikit-Learn machine learning models\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(22)\n",
    "    # Make a dictionary to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        #Fit the model to the data\n",
    "        model.fit(X_train,y_train)\n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = model_fit_and_score(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be96ec8",
   "metadata": {},
   "source": [
    "## Model Comparison - Initial Model Accuracy comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4010727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\n",
    "model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a69e76",
   "metadata": {},
   "source": [
    "# 5. Model Tuning with GridSearchCV\n",
    "\n",
    "## K-Nearest Neighbor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different KNeighborsClassifier hyperparameters\n",
    "knn_grid = {\"n_neighbors\": range(1, 4, 1),\n",
    "              \"weights\": [\"uniform\", \"distance\"],\n",
    "              \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "              \"leaf_size\": range(1, 4, 4)}\n",
    "\n",
    "# Setup grid hyperparameter search for KNeighborsClassifier\n",
    "knn_g = KNeighborsClassifier()\n",
    "np.random.seed(22)\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3)\n",
    "grid_knn = GridSearchCV(estimator=knn_g, param_grid=knn_grid, n_jobs=1, cv=cv, scoring=\"accuracy\", error_score=0)\n",
    "grid_knn_results = grid_knn.fit(X_train, y_train);\n",
    "\n",
    "#tune for best model and capture time\n",
    "start = time.time()\n",
    "knn_final_model = knn_g.set_params(**grid_knn_results.best_params_)\n",
    "knn_final_model.fit(X_train, y_train)\n",
    "knn_y_pred = knn_final_model.predict(X_test)\n",
    "elapsed_time = (time.time() - start)\n",
    "knn_y_proba = knn_final_model.predict_proba(X_test)\n",
    "print(\"Time taken : \", elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92604e",
   "metadata": {},
   "source": [
    "## Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97908e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different LogisticRegression hyperparameters\n",
    "logreg_grid = {\"C\": np.logspace(0.1, 0.5, 1, 1.5),\n",
    "                  \"solver\": [\"liblinear\"],\n",
    "                  \"penalty\": [\"l1\", \"l2\"],\n",
    "                  \"max_iter\": [100, 1000, 2500, 5000]}\n",
    "\n",
    "# Setup grid hyperparameter search for LogisticRegression\n",
    "logreg_g = LogisticRegression()\n",
    "np.random.seed(22)\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3)\n",
    "grid_logreg = GridSearchCV(estimator=logreg_g, param_grid=logreg_grid, n_jobs=1, cv=cv, scoring=\"accuracy\", error_score=0)\n",
    "grid_logreg_results = grid_logreg.fit(X_train, y_train);\n",
    "\n",
    "#tune for best model and capture time\n",
    "start = time.time()\n",
    "logreg_final_model = logreg_g.set_params(**grid_logreg_results.best_params_)\n",
    "logreg_final_model.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg_final_model.predict(X_test)\n",
    "elapsed_time = (time.time() - start)\n",
    "logreg_y_proba = logreg_final_model.predict_proba(X_test)\n",
    "print(\"Time taken : \", elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8266d0",
   "metadata": {},
   "source": [
    "## Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different LogisticRegression hyperparameters\n",
    "dectree_grid = {\"max_leaf_nodes\": range(2000, 2900, 300),\n",
    "                  \"criterion\": [\"gini\", \"entropy\"],\n",
    "                  \"min_samples_split\": [2, 4],\n",
    "                  \"max_depth\": range(500, 2000, 500)}\n",
    "\n",
    "# Setup grid hyperparameter search for LogisticRegression\n",
    "dectree_g = DecisionTreeClassifier()\n",
    "np.random.seed(22)\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3)\n",
    "grid_dectree = GridSearchCV(estimator=dectree_g, param_grid=dectree_grid, n_jobs=1, \n",
    "                            cv=cv, scoring=\"accuracy\", error_score=0)\n",
    "grid_dectree_results = grid_dectree.fit(X_train, y_train);\n",
    "\n",
    "#tune for best model and capture time\n",
    "start = time.time()\n",
    "dectree_final_model = dectree_g.set_params(**grid_dectree_results.best_params_)\n",
    "dectree_final_model.fit(X_train, y_train)\n",
    "dectree_y_pred = dectree_final_model.predict(X_test)\n",
    "elapsed_time = (time.time() - start)\n",
    "dectree_y_proba = dectree_final_model.predict_proba(X_test)\n",
    "print(\"Time taken : \", elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17b50d",
   "metadata": {},
   "source": [
    "# 6. Evaluation of tuned classification models\n",
    "\n",
    "## A. Quick print of classification report, confusion matrix and best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== K-Nearest Neighbor Evaluation ==\")\n",
    "print(\"Classification report====\")\n",
    "print(classification_report(y_test,knn_y_pred))\n",
    "print(\"Confusion Matrix====\")\n",
    "print(confusion_matrix(knn_y_pred, y_test))\n",
    "print(\"best_params====\")\n",
    "print(grid_knn_results.best_params_)\n",
    "print(\"\")\n",
    "\n",
    "print(\"== Logistic Regression Evaluation ==\")\n",
    "print(\"Classification report====\")\n",
    "print(classification_report(y_test,logreg_y_pred))\n",
    "print(\"Confusion Matrix====\")\n",
    "print(confusion_matrix(logreg_y_pred, y_test))\n",
    "print(\"best_params====\")\n",
    "print(grid_logreg_results.best_params_)\n",
    "print(\"\")\n",
    "\n",
    "print(\" == Decision Tree Evaluation ==\")\n",
    "print(\"Classification report====\")\n",
    "print(classification_report(y_test,dectree_y_pred))\n",
    "print(\"Confusion Matrix====\")\n",
    "print(confusion_matrix(dectree_y_pred, y_test))\n",
    "print(\"\")\n",
    "print(\"best_params====\")\n",
    "print(grid_dectree_results.best_params_)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477cdad",
   "metadata": {},
   "source": [
    "## B. ROC curve and AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC curves for the 3 models\n",
    "\n",
    "plot = skplt.metrics.plot_roc(y_test, knn_y_proba)\n",
    "plt.title(\"ROC Curves - K-Nearest Neighbors\");\n",
    "\n",
    "plot = skplt.metrics.plot_roc(y_test, logreg_y_proba)\n",
    "plt.title(\"ROC Curves - Logistic Regression\");\n",
    "\n",
    "plot = skplt.metrics.plot_roc(y_test, dectree_y_proba)\n",
    "plt.title(\"ROC Curves - Decision Tree\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797d321",
   "metadata": {},
   "source": [
    "## C. Confusion Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "\n",
    "def plot_conf_mat(y_pred, y_test, graph_title):\n",
    "    \"\"\"\n",
    "    Plots a nice looking confusion matrix using Seaborn's heatmap()\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "    ax = sns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cmap=\"coolwarm_r\", linewidths=0.5, fmt ='g')\n",
    "    plt.xlabel(\"Predicted wine class\")\n",
    "    plt.ylabel(\"True wine class\")\n",
    "    plt.title(graph_title)\n",
    "    \n",
    "    bottom, top = ax.get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d57d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_mat(y_test, knn_y_pred, \"KNNeighbor confusion matrix\")\n",
    "plot_conf_mat(y_test, logreg_y_pred, \"LogisticRegresssion Confusion matrix\")\n",
    "plot_conf_mat(y_test, dectree_y_pred, \"DecisionTree Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37c65b",
   "metadata": {},
   "source": [
    "## D. Cross Validation with model's best hyperparamter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and Sampling the whole wine dataset in parameter fot cross-validation implementation\n",
    "X_cross_val = scaler.fit_transform(X)\n",
    "X_cross_val = pd.DataFrame(X_cross_val, columns=X_pretrain.columns)\n",
    "X_cross_val.head()\n",
    "\n",
    "X_cv, y_cv = smote_tomek.fit_resample(X_cross_val, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_val_best_param (clf, title):\n",
    "    # Cross-validated accuracy score\n",
    "    cv_acc = np.mean(cross_val_score(clf, X_cv, y_cv, cv=10, scoring=\"accuracy\")) # accuracy as scoring \n",
    "    #print(title, \"corss-validated accuracy score = \", cv_acc)\n",
    "    #print(\"\")\n",
    "\n",
    "    # Cross-validated precision score\n",
    "    cv_precision = np.mean(cross_val_score(clf, X_cv, y_cv, cv=10, scoring=\"precision\")) # precision as scoring\n",
    "    #print(title, \"corss-validated precision score = \", cv_precision)\n",
    "    #print(\"\")\n",
    "\n",
    "    # Cross-validated recall score\n",
    "    cv_recall = np.mean(cross_val_score(clf, X_cv, y_cv, cv=10, scoring=\"recall\")) # recall as scoring\n",
    "    #print(title, \"corss-validated recall score = \", cv_recall)\n",
    "    #print(\"\")\n",
    "\n",
    "    # Cross-validated recall score\n",
    "    cv_f1 = np.mean(cross_val_score(clf, X_cv, y_cv, cv=10, scoring=\"f1\")) # recall as F1\n",
    "    #print(title, \"cross-validated F1 score = \", cv_f1)\n",
    "    #print(\"\")\n",
    "\n",
    "    # Visualizing cross-validated metrics\n",
    "    print(title)\n",
    "    cv_metrics = pd.DataFrame({\"Accuracy\": cv_acc,\n",
    "                                \"Precision\": cv_precision,\n",
    "                                \"Recall\": cv_recall,\n",
    "                                \"F1\": cv_f1},\n",
    "                              index=[0])\n",
    "    print(cv_metrics)\n",
    "    cv_metrics.T.plot.bar(title=title, legend=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a761ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_best_param(knn_g, \"K_Nearest neighbor model cross-validation\")\n",
    "print(\"=========================================================================\")\n",
    "cross_val_best_param(dectree_g, \"Decision Tree model cross-validation\")\n",
    "print(\"=========================================================================\")\n",
    "cross_val_best_param(logreg_g, \"Logistic Regression model cross-validation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
